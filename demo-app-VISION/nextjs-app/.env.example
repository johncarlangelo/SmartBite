# Ollama Configuration
# Base URL for Ollama service
OLLAMA_BASE_URL=http://localhost:11434

# Vision Model - Used for image analysis (requires vision capabilities)
# Options: llava:7b, llava:13b, bakllava
OLLAMA_VISION_MODEL=llava:7b

# Recommendation Model - Used for text-based recommendations
# Using smaller/faster model for speed since recommendations don't need vision
# Options: llama3.2:3b, llama3.1:3b, llama2:7b
OLLAMA_RECOMMENDATION_MODEL=llama3.2:3b

# Online Model - Alternative model for online mode
OLLAMA_ONLINE_MODEL=llava:7b
